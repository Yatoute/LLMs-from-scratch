{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48aa6fe6",
   "metadata": {},
   "source": [
    "## Fine-tuning pour la classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6724950d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 02:56:26.426300: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Mapping, Any, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from gptlight.tokenizer import GPTTokenizer\n",
    "from gptlight.models import GPTModel\n",
    "from gptlight.config import GPTConfig\n",
    "from gptlight.training import Trainer, load_model, save_model, classification_loss\n",
    "from gptlight.utils import fetch_sms_spam_collection\n",
    "from gptlight.data import ClassifcationDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7a96e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device : cpu\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(123)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a165c2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPTTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324e81e2",
   "metadata": {},
   "source": [
    "Jusqu'ici, nous avons code l'architecture du LLM, effectue le pre-entrainement et appris a importer des poids pre-entraines depuis une source externe comme OpenAI. Il est temps d'en recolter les fruits en ajustant le LLM sur une tâche cible, par exemple la classification de texte. L'exemple concret etudié consiste à déterminer si un message est \"spam\" ou \"not spam\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c92ec16",
   "metadata": {},
   "source": [
    "## Différentes catégories de fine-tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26379e9",
   "metadata": {},
   "source": [
    "Les approches de fine-tuning les plus courantes sont le fine-tuning par instructions et le fine-tuning pour la classification. Le fine-tuning par instructions entraine le modèle sur des tâches décrites en langage naturel afin d'ameliorer son comprehension des consignes.\n",
    "\n",
    "Le fine-tuning pour la classification, familier a tout praticien de l'apprentissage automatique, apprend au modèle à reconnaitre un ensemble de classes (\"spam\" vs \"not spam\", par exemple). Les applications incluent aussi bien l'identification d'especes vegetales a partir d'images que la categorisation d'articles (sport, politique, technologie) ou la distinction tumeurs benignes/malignes.\n",
    "\n",
    "Un modèle classeur reste limité aux étiquettes vues pendant l'entraînement. A l'inverse, un modèle ajusté par instructions reste généraliste mais est plus difficile à développer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0987cc",
   "metadata": {},
   "source": [
    "## Choisir la bonne approche\n",
    "\n",
    "Le fine-tuning par instructions augmente la flexibilite du modele pour repondre a des consignes complexes et variees. Il necessite toutefois davantage de donnees et de calcul. Le fine-tuning pour la classification est ideal lorsque l'on souhaite affecter des etiquettes predefinies (analyse de sentiment, detection de spam) avec un volume de donnees reduit. Le choix depend donc du type de taches visees et des ressources disponibles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a3e2c8",
   "metadata": {},
   "source": [
    "## Preparation du jeu de donnees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c5bd37",
   "metadata": {},
   "source": [
    "Nous allons modifier puis ajuster pour la classification le GPT precedemment implemente et pre-entraine. Premieres etapes : telecharger et preparer le jeu de donnees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f539d2b3",
   "metadata": {},
   "source": [
    "> Nous utilisons la methode `fetch_sms_spam_collection` du module `gptlight.datasets` pour telecharger le corpus dans un DataFrame pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b64d182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                               Text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = fetch_sms_spam_collection()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928f5387",
   "metadata": {},
   "source": [
    "Observons la distribution des etiquettes :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "068bdf06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b1812e",
   "metadata": {},
   "source": [
    "Pour rester sur un corpus reduit (ce qui accelere le fine-tuning), nous sous-echantillonnons le jeu de donnees pour conserver 747 exemples par classe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee693576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     747\n",
       "spam    747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_spam = sum(df.Label==\"spam\")\n",
    "ham_subset = df[df.Label==\"ham\"].sample(num_spam, random_state=123)\n",
    "df_subset = pd.concat([\n",
    "    ham_subset, df[df.Label==\"spam\"]\n",
    "])\n",
    "df_subset[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ac45c4",
   "metadata": {},
   "source": [
    "Nous convertissons ensuite les etiquettes textuelles \"ham\" et \"spam\" en valeurs entieres 0 et 1 :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84442876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset[\"Label\"] = df_subset[\"Label\"].map({\"ham\":0, \"spam\":1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2747918",
   "metadata": {},
   "source": [
    "Nous definissons enfin `random_split` afin de separer les donnees en 70 % train, 10 % validation et 20 % test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85b26845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df:pd.DataFrame, train_frac, val_frac, random_state=None):\n",
    "    \n",
    "    df = df.sample(\n",
    "        frac=1, random_state=random_state\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    train_end = int(len(df)*train_frac)\n",
    "    val_end = train_end + int(len(df)*val_frac)\n",
    "    \n",
    "    train_df = df[:train_end]\n",
    "    val_df = df[train_end:val_end]\n",
    "    test_df = df[val_end:]\n",
    "    \n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54777fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = random_split(df_subset, train_frac=0.7, val_frac=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f739b7a1",
   "metadata": {},
   "source": [
    "## Creation des data loaders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342f908d",
   "metadata": {},
   "source": [
    "Auparavant, nous utilisions des fenetres glissantes de taille fixe pour produire des batches homogenes. Les messages SMS ont des longueurs variables, nous devons donc uniformiser les sequences au sein d'un batch.\n",
    "\n",
    "Deux options : tronquer tous les messages a la longueur minimale, ou completer chaque message jusqu'a la longueur maximale. La troncature peut supprimer trop d'information; nous choisissons donc le padding.\n",
    "\n",
    "Concretement, nous ajoutons des tokens de remplissage jusqu'a atteindre la longueur maximale observee, en reutilisant le token `<|endoftext|>` (ID 50256) directement au niveau des IDs plutot qu'au niveau texte.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b94827",
   "metadata": {},
   "source": [
    "> Consultez la classe `ClassificationDataset` dans `gptlight.data.datasets` pour voir comment ces etapes sont mise en oeuvre.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0cf60fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ClassifcationDataset(\n",
    "    input_texts=train_df[\"Text\"],\n",
    "    target_labels=train_df[\"Label\"],\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1a3b53",
   "metadata": {},
   "source": [
    "La plus longue sequence est accessible via l'attribut `max_length` du dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaa7db2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4677596b",
   "metadata": {},
   "source": [
    "Le programme affiche 120 : la sequence la plus longue comprend 120 tokens, ce qui reste bien en dessous de la longueur de contexte 1 024 du modele. Si vos textes depassent cette limite, passez `max_length=1024` pour rester compatible avec GPT-2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f0e6ca",
   "metadata": {},
   "source": [
    "Nous appliquons ensuite le meme padding aux ensembles de validation et de test, en tronquant eventuellement les sequences qui excederaient la longueur maximale du train.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94dbf0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = ClassifcationDataset(\n",
    "    input_texts=val_df[\"Text\"],\n",
    "    target_labels=val_df[\"Label\"],\n",
    "    max_lenght=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = ClassifcationDataset(\n",
    "    input_texts=test_df[\"Text\"],\n",
    "    target_labels=test_df[\"Label\"],\n",
    "    max_lenght=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d00e02",
   "metadata": {},
   "source": [
    "> Creation des DataLoader PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b62ac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers =0\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e2dbda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   56,    64,   655,  5149,   450,    83,   294,    83,  4519,   492,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [   40,  1464,  8537,   351,   345,    13,   554,  1109,  1312,   761,\n",
      "          1637,   460,   345,  5298,   502,    30, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [45048,   471,   460,  1624,   362, 24791,  5752,   317, 26878,   362,\n",
      "           327, 12391,   287, 10010,   287,  3389,   393, 12391,  6979, 11462,\n",
      "          4889,  7769,  3312, 11442,    19, 27988,   284,  1624, 26136,     5,\n",
      "         32274,  7324,    13,    82,   907,  1073,    13,  3262,  1575, 14988,\n",
      "            18,    13,  2425,  9806,   220, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [ 1135,   460,   467,   604,   304,  3487,  5560,   689,   706,   674,\n",
      "         18951,   986,   220,   220, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [   35, 37606,    13,   843,   345,  1839,   470,   423,   284,  5490,\n",
      "           546,   502,  2282, 15529, 39356,   284,   345,  7471,    13,  4525,\n",
      "          1312,   531,   938,  1755,    11,   345,   466,  4232,   345,   765,\n",
      "           290,  1312,  1183,   466,   262,   976,    13, 12689,    13, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [25206,   502,   534, 15294, 21912,     8, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [ 5122, 10691,  2139,   468,   587,  1965,   362,  2800,   471,   416,\n",
      "          2130, 15800,     0, 42815,  7769,  2713, 34583,  1507,  2154, 20229,\n",
      "           477,   481,   307,  4602,    13,   350,  9864,  1140,  5705,    11,\n",
      "           337,  2075,   513,    52,    57,  6640,    79, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [ 8491,   345, 12876,    13,  1867,  1645,   284, 17438,   588,   428,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]) tensor([0, 0, 1, 0, 0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "input_batch, target_batch = next(iter(train_loader))\n",
    "print(input_batch, target_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "006c3d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0d56e2",
   "metadata": {},
   "source": [
    "Chaque batch contient huit exemples de 120 tokens, et le tenseur de labels fournit les classes correspondantes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996d1b86",
   "metadata": {},
   "source": [
    "## Initialiser un modele avec des poids pre-entraines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10d55eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_SMALL_CONFIG_124M = GPTConfig(\n",
    "    vocab_size=50257,\n",
    "    context_length=1024,\n",
    "    emb_dim=768,\n",
    "    n_heads=12,\n",
    "    n_layers=12,\n",
    "    drop_rate=0.0,\n",
    "    qkv_bias=True\n",
    ")\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "gpt_model = GPTModel(GPT_SMALL_CONFIG_124M)\n",
    "gpt_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5905f06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = load_model(path=\"../assets/checkpoints/gpt.pt\", device=device)\n",
    "gpt_model.load_state_dict(state_dict=state[\"model_state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "477e9299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves slowly and slowly in all parts of the galaxy, from asteroids to space and\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "tokenizer = GPTTokenizer()\n",
    "token_ids = gpt_model.generate(\n",
    "    idx=tokenizer.encode(INPUT_PROMPT).unsqueeze(0).to(device),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_SMALL_CONFIG_124M.context_length,\n",
    "    top_k=15,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", tokenizer.decode(token_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b673397",
   "metadata": {},
   "source": [
    "Avant le fine-tuning, testons le modele actuel avec une instruction pour voir s'il sait deja detecter le spam :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df84e2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "text = (\n",
    "\"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "\" 'You are a winner you have been specially\"\n",
    "\" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "token_ids = gpt_model.generate(\n",
    "    idx=tokenizer.encode(text).unsqueeze(0).to(device),\n",
    "    max_new_tokens=23,\n",
    "    context_size=GPT_SMALL_CONFIG_124M.context_length,\n",
    "    #top_k=15,\n",
    "    #temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", tokenizer.decode(token_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1647b0ae",
   "metadata": {},
   "source": [
    "La reponse montre qu'il suit mal la consigne, ce qui est logique : seul le pre-entrainement a ete effectue. Passons a la preparation pour la classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238477c7",
   "metadata": {},
   "source": [
    "## Ajouter une tete de classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db4661c",
   "metadata": {},
   "source": [
    "Pour adapter le LLM, nous remplaçons la tete de sortie (50 257 dimensions) par une couche ne renvoyant que deux logits (0 = not spam, 1 = spam). Commencons par afficher l'architecture actuelle pour savoir ce que nous modifions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "eeafa279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): GPTTransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): GPTTransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): GPTTransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): GPTTransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): GPTTransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): GPTTransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): GPTTransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): GPTTransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): GPTTransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): GPTTransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): GPTTransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): GPTTransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(gpt_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98260d81",
   "metadata": {},
   "source": [
    "Jusqu'ici, `GPTModel` comprend les embeddings, douze blocs transformeur, une layer norm finale et la tête de langage. Cette tête produit une distribution sur l'ensemble du vocabulaire pour la prediction du prochain token.\n",
    "\n",
    "Dans le cadre de la classification, nous n'avons besoin que de quelques logits. L'objectif est donc de reutiliser les representations internes deja apprises tout en specialisant la derniere partie du reseau. Conformement aux principes de transfert, les couches basses capturent des regularites linguistiques reutilisables; seules les couches hautes doivent etre ajustées.\n",
    "\n",
    "Première étape : geler les couches existantes pour conserver leurs poids pre-entraines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e271921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in gpt_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070a61d4",
   "metadata": {},
   "source": [
    "Ensuite, nous remplaçons `model.out_head` par une couche qui projette vers deux dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "066b6781",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "gpt_model.out_head = torch.nn.Linear(GPT_SMALL_CONFIG_124M.emb_dim, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec49c1d",
   "metadata": {},
   "source": [
    "Par defaut, la nouvelle tête a `requires_grad=True`. C'est la seule partie strictement necessaire a entrainer, mais on peut aussi laisser le dernier bloc transformeur et la LayerNorm finale apprenables pour gagner en performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d95c0d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in gpt_model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "for param in gpt_model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed331ab",
   "metadata": {},
   "source": [
    "Pour encapsuler ces operations, nous definissons la classe `GPTClassifier`, derivée de `GPTModel`, qui fige les couches internes et adapte la tête de classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "feeafffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTClassifier(GPTModel):\n",
    "        \n",
    "    def __init__(self, cfg:GPTConfig, num_classes:int=2):\n",
    "        super().__init__(cfg)\n",
    "        \n",
    "        self.cfg = cfg\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "      \n",
    "        self.out_head = torch.nn.Linear(self.cfg.emb_dim, num_classes)\n",
    "        \n",
    "        for param in self.trf_blocks[-1].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        for param in self.final_norm.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201f6dce",
   "metadata": {},
   "source": [
    "> Chargement les poids pré-entraînés du GPT original dans notre classifier\n",
    "\n",
    "Comme le checkpoint pré-entraîné contient aussi les poids de l’ancienne tête de langage, dont la forme ne correspond pas à la tête de classification, nous filtrons simplement ces paramètres. Ainsi, seuls les poids compatibles du modèle GPT original sont chargés, tandis que la nouvelle tête de classification reste initialisée pour le fine-tuning supervisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dc1016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTClassifier(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): GPTTransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "gpt_classifier = GPTClassifier(GPT_SMALL_CONFIG_124M, num_classes=2)\n",
    "gpt_classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7384c9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/yatoute/workspace/AI/Labs/LLMs-from-scratch/gptlight/src/gptlight/training/checkpoint.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(path, map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['out_head.weight', 'out_head.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_state = load_model(path=\"../assets/checkpoints/gpt.pt\", device=device)\n",
    "state_dict_for_classif = {\n",
    "    k: v for k, v in gpt_state[\"model_state\"].items()\n",
    "    if not k.startswith(\"out_head.\")\n",
    "}\n",
    "gpt_classifier.load_state_dict(state_dict_for_classif, strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd706ba",
   "metadata": {},
   "source": [
    "## Calculer la perte et l'accuracy de classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e53608",
   "metadata": {},
   "source": [
    "Avant le fine-tuning, implementons les fonctions d'evaluation. Comme pour la generation, nous appliquons softmax sur les logits puis `argmax` pour obtenir l'etiquette prevue (spam ou not spam).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52600064",
   "metadata": {},
   "source": [
    "### Accuracy de classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704f11fb",
   "metadata": {},
   "source": [
    "L'accuracy mesure la proportion de predictions correctes sur un ensemble donne.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5174f38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_accuracy_loader(\n",
    "    model:GPTClassifier,\n",
    "    data_loader:DataLoader,\n",
    "    device:torch.device,\n",
    "    num_batches:int=None \n",
    ") -> float:\n",
    "    \n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    \n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "        \n",
    "    corrects_predictions, num_samples =0,0\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        \n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        input_batch = input_batch.to(device)\n",
    "        target_batch = target_batch.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(input_batch)\n",
    "        \n",
    "        logits = logits[:, -1, :]\n",
    "        \n",
    "        predicted_labels = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        num_samples += predicted_labels.shape[0]\n",
    "        \n",
    "        corrects_predictions += (\n",
    "            predicted_labels == target_batch\n",
    "        ).sum().item()\n",
    "        \n",
    "    \n",
    "    return corrects_predictions/num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b9f10f",
   "metadata": {},
   "source": [
    "Servons-nous de la fonction pour estimer les accuracies sur les differents splits a partir de 10 batches chacun, pour aller plus vite :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "779a3472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 48.75%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = classification_accuracy_loader(\n",
    "    model=gpt_classifier,\n",
    "    data_loader=train_loader,\n",
    "    device=device,\n",
    "    num_batches=10\n",
    ")\n",
    "\n",
    "val_accuracy = classification_accuracy_loader(\n",
    "    model=gpt_classifier,\n",
    "    data_loader=val_loader,\n",
    "    device=device,\n",
    "    num_batches=10\n",
    ")\n",
    "\n",
    "test_accuracy = classification_accuracy_loader(\n",
    "    model=gpt_classifier,\n",
    "    data_loader=test_loader,\n",
    "    device=device,\n",
    "    num_batches=10\n",
    ")\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa798e4",
   "metadata": {},
   "source": [
    "L'accuracy tourne autour de 50 %, soit le niveau du hasard. Pour la faire progresser, il faut fine-tuner le modele, ce qui suppose de definir une perte differentiable. Nous utilisons une cross-entropy qui ne regarde que le dernier token `model(input_batch)[:, -1, :]`, contrairement au pre-entrainement ou tous les tokens etaient pris en compte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c8ab7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_loss(logits:torch.Tensor, targets:torch.Tensor):\n",
    "    \"\"\"\n",
    "    Cross-entropy loss for classification fine-tuning.\n",
    "\n",
    "    Args:\n",
    "        logits:  (B, T, V)\n",
    "        targets: (B, T)\n",
    "\n",
    "    Returns:\n",
    "        Scalar tensor (loss)\n",
    "    \"\"\"\n",
    "    \n",
    "    return F.cross_entropy(\n",
    "        logits[:, -1, :],\n",
    "        targets\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813ec0ae",
   "metadata": {},
   "source": [
    "`classification_loss` retourne la perte pour un batch; pour couvrir l'ensemble d'un loader, nous utilisons `classification_loss_loader` comme precedemment :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ad1261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_loss_loader(\n",
    "    model:GPTClassifier,\n",
    "    data_loader:DataLoader,\n",
    "    device:torch.device,\n",
    "    num_batches:int=None\n",
    ")-> float :\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    total_loss=0\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        \n",
    "        if i >= num_batches :\n",
    "            break\n",
    "        \n",
    "        input_batch = input_batch.to(device)\n",
    "        target_batch = target_batch.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(input_batch)\n",
    "        batch_loss = classification_loss(logits, target_batch).item()\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "    \n",
    "    return total_loss/num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "227c4171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.9464\n",
      "Validation loss: 5.3439\n",
      "Test loss: 4.9671\n"
     ]
    }
   ],
   "source": [
    "train_loss = classification_loss_loader(\n",
    "    model=gpt_classifier,\n",
    "    data_loader=train_loader,\n",
    "    device=device,\n",
    "    num_batches=10\n",
    ")\n",
    "\n",
    "val_loss = classification_loss_loader(\n",
    "    model=gpt_classifier,\n",
    "    data_loader=val_loader,\n",
    "    device=device,\n",
    "    num_batches=10\n",
    ")\n",
    "\n",
    "test_loss = classification_loss_loader(\n",
    "    model=gpt_classifier,\n",
    "    data_loader=test_loader,\n",
    "    device=device,\n",
    "    num_batches=10\n",
    ")\n",
    "\n",
    "print(f\"Training loss: {train_loss:.4f}\")\n",
    "print(f\"Validation loss: {val_loss:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba23fbd8",
   "metadata": {},
   "source": [
    "## Fine-tuning du modele sur des donnees supervisées\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a683e7d",
   "metadata": {},
   "source": [
    "Comme lors du pre-entrainement, nous utilisons la classe `Trainer` mais avec la perte `classification_loss`, qui n'evalue que le dernier token pour apprendre a classer spam vs not spam.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b65fb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/5] train_loss=1.0035 | val_loss=0.5847\n",
      "[Epoch 2/5] train_loss=0.4556 | val_loss=0.3946\n",
      "[Epoch 3/5] train_loss=0.3920 | val_loss=0.3533\n",
      "[Epoch 4/5] train_loss=0.3833 | val_loss=0.4426\n",
      "[Epoch 5/5] train_loss=0.3817 | val_loss=0.3158\n",
      "Training completed in 18.88 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(gpt_classifier.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "num_epochs = 5\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=gpt_classifier,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    loss_fn=classification_loss\n",
    ")\n",
    "history = trainer.fit(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=num_epochs\n",
    ")\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b49c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/10] train_loss=0.2249 | val_loss=0.0910\n",
      "[Epoch 2/10] train_loss=0.1092 | val_loss=0.0718\n",
      "[Epoch 3/10] train_loss=0.0750 | val_loss=0.0585\n",
      "[Epoch 4/10] train_loss=0.0598 | val_loss=0.0792\n",
      "[Epoch 5/10] train_loss=0.0513 | val_loss=0.0549\n",
      "[Epoch 6/10] train_loss=0.0508 | val_loss=0.0540\n",
      "[Epoch 7/10] train_loss=0.0441 | val_loss=0.0626\n",
      "[Epoch 8/10] train_loss=0.0339 | val_loss=0.0818\n",
      "[Epoch 9/10] train_loss=0.0282 | val_loss=0.0773\n",
      "[Epoch 10/10] train_loss=0.0236 | val_loss=0.0613\n",
      "Training completed in 39.25 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "num_epochs = 10\n",
    "\n",
    "history2 = trainer.fit(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=num_epochs\n",
    ")\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7bc0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history['train_loss'].extend(history2['train_loss'])\n",
    "history['val_loss'].extend(history2['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6a02468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning_curve(history):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
    "    ax1.plot(epochs, history[\"train_loss\"], label=\"Training loss\")\n",
    "    ax1.plot( epochs, history[\"val_loss\"], linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Cross-entropy\")\n",
    "    ax1.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_learning_curve(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381c4e37",
   "metadata": {},
   "source": [
    "La courbe d’apprentissage met en évidence une **phase d’apprentissage stable et efficace** : les pertes d’entraînement et de validation diminuent régulièrement durant les dix premières époques, ce qui montre que le modèle parvient à extraire progressivement des représentations utiles pour la tâche de classification.\n",
    "\n",
    "À partir de l’**11ᵉ époque**, on observe une **légère dégradation de la performance sur le jeu de validation**, tandis que la perte d’entraînement continue de baisser. Ce comportement suggère que le modèle commence à **sur-apprendre** les spécificités du jeu d’entraînement plutôt que les régularités générales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "33792737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/5] train_loss=0.5955 | val_loss=0.4212\n",
      "[Epoch 2/5] train_loss=0.1699 | val_loss=0.0681\n",
      "[Epoch 3/5] train_loss=0.0836 | val_loss=0.0605\n",
      "[Epoch 4/5] train_loss=0.0706 | val_loss=0.0552\n",
      "[Epoch 5/5] train_loss=0.0633 | val_loss=0.0540\n",
      "Training completed in 22.33 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "torch.manual_seed(123)\n",
    "gpt_classifier = GPTClassifier(cfg=GPT_SMALL_CONFIG_124M)\n",
    "gpt_classifier.load_state_dict(state_dict_for_classif, strict=False)\n",
    "optimizer = torch.optim.AdamW(gpt_classifier.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=gpt_classifier,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    loss_fn=classification_loss\n",
    ")\n",
    "history = trainer.fit(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=num_epochs\n",
    ")\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44239e0c",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant calculer les metriques finales sur train, validation et test en parcourant tous les exemples :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6bc16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c8cec1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 98.37%\n",
      "Validation accuracy: 97.92%\n",
      "Test accuracy: 96.96%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = classification_accuracy_loader(\n",
    "    model=gpt_classifier,\n",
    "    data_loader=train_loader,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "val_accuracy = classification_accuracy_loader(\n",
    "    model=gpt_classifier,\n",
    "    data_loader=val_loader,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "test_accuracy = classification_accuracy_loader(\n",
    "    model=gpt_classifier,\n",
    "    data_loader=test_loader,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91356fa",
   "metadata": {},
   "source": [
    "Les performances obtenues après fine-tuning montrent que le modèle a su apprendre efficacement la structure du jeu de données tout en conservant une bonne capacité de généralisation. L’accuracy d’entraînement de 98,37 % indique que le modèle s’adapte très bien aux exemples vus lors de l’apprentissage, tandis que l’accuracy de validation de 97,92 % confirme que cette compréhension se transfère de manière robuste à des données nouvelles. Enfin, l’accuracy de test de 96,96 % montre que le modèle reste performant lorsqu’il est confronté à des exemples réellement inédits, sans signe majeur de surapprentissage.\n",
    "\n",
    "Ces résultats sont déjà très satisfaisants, mais ils pourraient être améliorés en ajustant certains hyperparamètres, comme augmenter le taux de dropout ou renforcer le weight decay dans l’optimiseur, afin d’obtenir un entraînement plus robuste et mieux régularisé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dce77db",
   "metadata": {},
   "source": [
    "## Utiliser le LLM comme classifieur de spam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08664a3",
   "metadata": {},
   "source": [
    "Apres fine-tuning et evaluation, nous exploitons la fonction `classify_review` : elle reprend la meme preparation que `ClassificationDataset`, encode le texte puis appelle le modele pour prédire si le message est spam ou non.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "53d7b297",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TRAIN_TEXTS_LENGTH = 120 #train_dataset.max_length\n",
    "\n",
    "def classify_review(\n",
    "    text: str,\n",
    "    model: GPTClassifier,\n",
    "    tokenizer: GPTTokenizer,\n",
    "    device: torch.device,\n",
    "    *,\n",
    "    max_length: Optional[int]=None,\n",
    "    pad_token_id: int = 50256,\n",
    ") -> Tuple[int, torch.Tensor]:\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    input_ids = tokenizer.encode(text).tolist()\n",
    "    \n",
    "    if max_length is None:\n",
    "        max_length = min(supported_context_length, max(MAX_TRAIN_TEXTS_LENGTH, len(input_ids)))\n",
    "        \n",
    "    input_ids = input_ids[:max_length]\n",
    "\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "\n",
    "    input_tensor = torch.tensor(\n",
    "        input_ids, dtype=torch.long, device=device\n",
    "    ).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "\n",
    "    predicted_label = torch.argmax(probs, dim=-1).item()\n",
    "\n",
    "    return predicted_label, probs.squeeze(0).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ea436074",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = (\n",
    "\"You are a winner you have been specially\"\n",
    "\" selected to receive $1000 cash or a $2000 award.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7c3c33fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, tensor([0.0243, 0.9757]))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_review(\n",
    "    text=text1,\n",
    "    model=gpt_classifier,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce88568",
   "metadata": {},
   "source": [
    "Dans ce premier exemple, le modele predit correctement \"spam\". Essayons un second message :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "8495f304",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = (\n",
    "\"Hey, just wanted to check if we're still on\"\n",
    "\" for dinner tonight? Let me know!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7a513e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, tensor([0.9963, 0.0037]))"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_review(\n",
    "    text=text2,\n",
    "    model=gpt_classifier,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0ecb22",
   "metadata": {},
   "source": [
    "Le modele renvoie a nouveau la bonne classe (\"not spam\"). Terminons en sauvegardant le modele pour le recharger sans refaire tout le fine-tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e515716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(\n",
    "    model=gpt_classifier,\n",
    "    path=\"../assets/checkpoints/gpt_spam_classifier.pt\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
